{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miniproject 1 - Neural Networks Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Caltech_Winter\\CS 155\\mini project1\\data\n"
     ]
    }
   ],
   "source": [
    "cd E:\\Caltech_Winter\\CS 155\\mini project1\\data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1000)\n",
      "(20000,)\n",
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "train_file = 'training_data.txt'\n",
    "test_file = 'test_data.txt'\n",
    "train_data = genfromtxt(train_file, delimiter=' ')\n",
    "test_data = genfromtxt(test_file, delimiter=' ')\n",
    "train_data = train_data[1:]\n",
    "X_test = test_data[1:]\n",
    "\n",
    "np.random.seed(123456)\n",
    "ind = np.random.permutation(train_data.shape[0])\n",
    "new_train_data = train_data[ind].astype(int)\n",
    "X_train = new_train_data[:, 1:]\n",
    "y_train = new_train_data[:, 0]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(20000, 1015)\n"
     ]
    }
   ],
   "source": [
    "bagging_train_file = './bagging_pca.txt'\n",
    "bagging_train_data = genfromtxt(bagging_train_file, delimiter='\\t')\n",
    "bagging_train_data = bagging_train_data[1:]\n",
    "bagging_X_train = bagging_train_data[:, 1:]\n",
    "bagging_y_train = bagging_train_data[:, 0]\n",
    "\n",
    "train_file = './training_data.txt'\n",
    "train_data = genfromtxt(train_file, delimiter=' ')\n",
    "train_data = train_data[1:]\n",
    "np.random.seed(123456)\n",
    "ind = np.random.permutation(train_data.shape[0])\n",
    "new_train_data = train_data[ind].astype(int)\n",
    "X_train = new_train_data[:, 1:]\n",
    "y_train = new_train_data[:, 0]\n",
    "\n",
    "X_train = np.concatenate([bagging_X_train, X_train], axis = 1)\n",
    "print(np.sum(y_train != bagging_y_train))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data[:, 1:]\n",
    "y_train = train_data[:, 0]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Networks Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NeuralRun(X_train, y_train, num_epoch, dropout, num_hidden_x, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_hidden_x[0], input_shape=(len(X_train[0]),)))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout[0]))\n",
    "    \n",
    "    model.add(Dense(num_hidden_x[1]))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout[1]))\n",
    "    \n",
    "    model.add(Dense(num_hidden_x[2]))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout[2]))\n",
    "    \n",
    "    model.add(Dense(num_hidden_x[3]))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout[3]))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # compile network\n",
    "    Adam = keras.optimizers.Adam(lr = learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "\n",
    "    fit = model.fit(X_train, y_train, batch_size = 32, epochs=num_epoch, verbose=1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CrossValidation(X_train, y_train, num_epoch, fold, dropout, num_hidden_x, learning_rate):\n",
    "\n",
    "    kf = KFold(n_splits=fold)\n",
    "    max_acc = 0\n",
    "    i = 1\n",
    "    sum_acc = 0\n",
    "    \n",
    "    print('Parameters: [Epochs] %d, [Fold] %d; [Dropout] %s, [Hidden X] %s, [Learning Rate] %s' \n",
    "          % (num_epoch, fold, dropout, num_hidden_x, learning_rate))\n",
    "    print('Start Training...')\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        print('Train on Fold %1d' % i)\n",
    "        i = i + 1\n",
    "        \n",
    "        model = NeuralRun(X_train[train_index], y_train[train_index], num_epoch, dropout, num_hidden_x, learning_rate, \\\n",
    "                          X_train[test_index], y_train[test_index])\n",
    "        \n",
    "        # Printing the accuracy of our model, according to the loss function specified in model.compile\n",
    "        score = model.evaluate(X_train[train_index], y_train[train_index], verbose=0)\n",
    "        print('Training accuracy:', score[1])\n",
    "        score = model.evaluate(X_train[test_index], y_train[test_index], verbose=0)\n",
    "        print('Test accuracy:', score[1])\n",
    "        \n",
    "        sum_acc += score[1]\n",
    "        if score[1] > max_acc:\n",
    "            max_model = model\n",
    "            max_acc = score[1]\n",
    "    \n",
    "    print('Best accuracy:', max_acc, 'Avg accuracy:', sum_acc / fold)\n",
    "    return max_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [Epochs] 3, [Fold] 5; [Dropout] [0.5, 0.5, 0.5, 0.5], [Hidden X] [200, 200, 200, 200], [Learning Rate] 0.001\n",
      "Start Training...\n",
      "Train on Fold 1\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 23s 1ms/step - loss: 0.5191 - acc: 0.7306 - val_loss: 0.3631 - val_acc: 0.8482\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.3553 - acc: 0.8531 - val_loss: 0.3510 - val_acc: 0.8522\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 16s 1ms/step - loss: 0.2999 - acc: 0.8818 - val_loss: 0.3455 - val_acc: 0.8542\n",
      "Training accuracy: 0.92675\n",
      "Test accuracy: 0.85425\n",
      "Train on Fold 2\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 26s 2ms/step - loss: 0.5039 - acc: 0.7468 - val_loss: 0.3667 - val_acc: 0.8482\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3495 - acc: 0.8560 - val_loss: 0.3622 - val_acc: 0.8485\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.2900 - acc: 0.8825 - val_loss: 0.3776 - val_acc: 0.8502\n",
      "Training accuracy: 0.932125\n",
      "Test accuracy: 0.85025\n",
      "Train on Fold 3\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 0.5174 - acc: 0.7319 - val_loss: 0.3556 - val_acc: 0.8490\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 15s 922us/step - loss: 0.3521 - acc: 0.8545 - val_loss: 0.3525 - val_acc: 0.8455\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2981 - acc: 0.8806 - val_loss: 0.3420 - val_acc: 0.8518\n",
      "Training accuracy: 0.9303125\n",
      "Test accuracy: 0.85175\n",
      "Train on Fold 4\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 28s 2ms/step - loss: 0.5064 - acc: 0.7462 - val_loss: 0.3701 - val_acc: 0.8452\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3542 - acc: 0.8522 - val_loss: 0.3721 - val_acc: 0.8345\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2956 - acc: 0.8834 - val_loss: 0.3560 - val_acc: 0.8417\n",
      "Training accuracy: 0.9325\n",
      "Test accuracy: 0.84175\n",
      "Train on Fold 5\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 28s 2ms/step - loss: 0.5084 - acc: 0.7447 - val_loss: 0.3592 - val_acc: 0.8448\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3462 - acc: 0.8555 - val_loss: 0.3556 - val_acc: 0.8420\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 20s 1ms/step - loss: 0.2931 - acc: 0.8806 - val_loss: 0.3405 - val_acc: 0.8462\n",
      "Training accuracy: 0.9344375\n",
      "Test accuracy: 0.84625\n",
      "Best accuracy: 0.85425 Avg accuracy: 0.8488499999999999\n"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "dropout = [0.5, 0.5, 0.5, 0.5]\n",
    "num_hidden_x = [200, 200, 200, 200]\n",
    "learning_rate = 0.001\n",
    "num_epoch = 3\n",
    "model = CrossValidation(X_train, y_train, num_epoch, fold, dropout, num_hidden_x, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'training_data.txt'\n",
    "test_file = 'test_data.txt'\n",
    "train_data = genfromtxt(train_file, delimiter=' ')\n",
    "test_data = genfromtxt(test_file, delimiter=' ')\n",
    "train_data = train_data[1:]\n",
    "\n",
    "np.random.seed(123456)\n",
    "ind = np.random.permutation(train_data.shape[0])\n",
    "new_train_data = train_data[ind].astype(int)\n",
    "\n",
    "# Here, y = 0 means bad review, and y = 1 means good review\n",
    "X_train = new_train_data[:, 1:]\n",
    "y_train = new_train_data[:, 0]\n",
    "y_stack = np.zeros((len(y_train), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 5\n",
    "dropout = 0.8\n",
    "num_hidden_x = 80\n",
    "learning_rate = 0.001\n",
    "num_epoch = 10\n",
    "kf = KFold(n_splits=fold)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    model = NeuralRun(X_train[train_index], y_train[train_index], num_epoch, dropout, num_hidden_x, learning_rate)\n",
    "    y_stack[test_index] = model.predict(X_train[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "y_stack_int = [1 if i > 0.5 else 0 for i in y_stack]\n",
    "\n",
    "with open(\"NN.txt\", 'a') as text_file:\n",
    "    text_file.write(\"Id,Prediction\\n\")\n",
    "    for i in range(len(y_stack_int)):\n",
    "        text_file.write(\"{},{}\\n\".format(i+1, y_stack_int[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.5132 - acc: 0.7376\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.3675 - acc: 0.8467\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.3238 - acc: 0.8688\n"
     ]
    }
   ],
   "source": [
    "fold = 5\n",
    "dropout = [0.65, 0.55, 0.45, 0.35]\n",
    "num_hidden_x = [200, 200, 200, 200]\n",
    "learning_rate = 0.001\n",
    "num_epoch = 3\n",
    "model = NeuralRun(X_train, y_train, num_epoch, dropout, num_hidden_x, learning_rate)\n",
    "y_test = model.predict(test_data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = model.predict(test_data[1:])\n",
    "y_test_int = [1 if i > 0.5 else 0 for i in y_test]\n",
    "\n",
    "with open(\"FinalTest.txt\", 'a') as text_file:\n",
    "    text_file.write(\"Id,Prediction\\n\")\n",
    "    for i in range(len(y_test_int)):\n",
    "        text_file.write(\"{},{}\\n\".format(i+1, y_test_int[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help for Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Fold Starts...\n",
      "1 Fold Complete...\n",
      "New Fold Starts...\n",
      "1 Fold Complete...\n",
      "New Fold Starts...\n",
      "1 Fold Complete...\n",
      "[0. 0. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "y_stack_ada = np.zeros(len(y_train))\n",
    "\n",
    "fold = 5\n",
    "kf = KFold(n_splits=fold)\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    if i > 2:\n",
    "        break\n",
    "    i = i + 1\n",
    "    print('New Fold Starts...')\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=4), algorithm=\"SAMME\", n_estimators=1500, learning_rate=1.0)\n",
    "    model.fit(X_train[train_index], y_train[train_index])\n",
    "    y_stack_ada[test_index] = model.predict(X_train[test_index])\n",
    "    print('1 Fold Complete...')\n",
    "\n",
    "print(y_stack_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_stack_int = [1 if i > 0.5 else 0 for i in y_stack_ada]\n",
    "\n",
    "with open(\"AdaBoost.txt\", 'a') as text_file:\n",
    "    text_file.write(\"Id,Prediction\\n\")\n",
    "    for i in range(len(y_stack_int)):\n",
    "        text_file.write(\"{},{}\\n\".format(i+1, y_stack_int[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
