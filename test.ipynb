{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Caltech_Winter\\CS 155\\mini project1\n"
     ]
    }
   ],
   "source": [
    "cd E:\\Caltech_Winter\\CS 155\\mini project1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "train_file = 'training_data.txt'\n",
    "test_file = 'test_data.txt'\n",
    "train_data = genfromtxt(train_file, delimiter=' ')\n",
    "test_data = genfromtxt(test_file, delimiter=' ')\n",
    "train_data = train_data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NeuralRun(X_train, y_train, num_epoch, dropout, num_hidden_x, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_hidden_x, input_shape=(len(X_train[0]),)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # compile network\n",
    "    Adam = keras.optimizers.Adam(lr = learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam, metrics=['accuracy'])\n",
    "\n",
    "    fit = model.fit(X_train, y_train, batch_size = 32, epochs=num_epoch, verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CrossValidation(train_data, num_epoch, fold, dropout, num_hidden_x, learning_rate):\n",
    "    \n",
    "    np.random.seed(123456)\n",
    "    ind = np.random.permutation(train_data.shape[0])\n",
    "    new_train_data = train_data[ind].astype(int)\n",
    "\n",
    "    # Here, y = 0 means bad review, and y = 1 means good review\n",
    "    X_train = new_train_data[:, 1:]\n",
    "    y_train = new_train_data[:, 0]\n",
    "\n",
    "    kf = KFold(n_splits=fold)\n",
    "    max_acc = 0\n",
    "    i = 1\n",
    "    \n",
    "    print('Parameters: [Epochs] %d, [Fold] %d; [Dropout] %s, [Hidden X] %d, [Learning Rate] %s' \n",
    "          % (num_epoch, fold, dropout, num_hidden_x, learning_rate))\n",
    "    print('Start Training...')\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        # print('Train on Fold %1d' % i)\n",
    "        i = i + 1\n",
    "        \n",
    "        model = NeuralRun(X_train[train_index], y_train[train_index], num_epoch, dropout, num_hidden_x, learning_rate)\n",
    "        \n",
    "        # Printing the accuracy of our model, according to the loss function specified in model.compile\n",
    "        score = model.evaluate(X_train[test_index], y_train[test_index], verbose=0)\n",
    "        # print('Test score:', score[0])\n",
    "        # print('Test accuracy:', score[1])\n",
    "        \n",
    "        if score[1] > max_acc:\n",
    "            max_model = model\n",
    "            max_acc = score[1]\n",
    "    \n",
    "    print('Best accuracy:', max_acc)\n",
    "    return max_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 5\n",
    "dropout = 0.2\n",
    "num_hidden_x = 70\n",
    "learning_rate = 0.002\n",
    "num_epoch = 20\n",
    "\n",
    "np.random.seed(123456)\n",
    "ind = np.random.permutation(train_data.shape[0])\n",
    "new_train_data = train_data[ind].astype(int)\n",
    "\n",
    "# Here, y = 0 means bad review, and y = 1 means good review\n",
    "X_train = new_train_data[:, 1:]\n",
    "y_train = new_train_data[:, 0]\n",
    "X_test = test_data[1:]\n",
    "\n",
    "model = NeuralRun(X_train, y_train, num_epoch, dropout, num_hidden_x, learning_rate)\n",
    "y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_int = [1 if i > 0.5 else 0 for i in y_test]\n",
    "\n",
    "with open(\"NNTest.txt\", 'a') as text_file:\n",
    "    text_file.write(\"Id,Prediction\\n\")\n",
    "    for i in range(len(y_test_int)):\n",
    "        text_file.write(\"{},{}\\n\".format(i+1, y_test_int[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3. 1. ... 0. 0. 0.]\n",
      " [2. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 1. ... 0. 0. 0.]\n",
      " [3. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
